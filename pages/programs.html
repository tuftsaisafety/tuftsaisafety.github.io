---
layout: base
title: TASSA | Programs
permalink: /programs/
---

<section id="programs">
    <div class="container">
        <h2>Programs</h2>
        <div class="programs-grid">
            <article class="program-card fellowship-container">
                <div class="fellowship-header">
                    <h3>Fellowships</h3>
                </div>
                <p>
                    <strong>Applications for the current cycle have closed.</strong> We will run
                    fellowships again in future semesters. Check back or
                    <a href="https://elist.tufts.edu/sympa/subscribe/tuftsaisafety" target="_blank" rel="noopener">join our mailing list</a>
                    for updates.
                </p>

                <p>
                    Our fellowships are 8-week, in-person reading groups that meet for 1.5hrs/wk. We
                    offer two ways to engage:
                </p>
                <ul>
                    <li>Self-contained with no outside readings nor capstone required.</li>
                    <li>
                        ~1 hour of required pre-reading each week plus a capstone project (e.g., a
                        policy brief/memo, implementing an ML paper, proposing a research project,
                        etc.).
                    </li>
                </ul>
                <p>
                    The fellowships are open to undergraduates, graduate students, and postdocs.
                    Catered lunch/dinner from local restaurants (not pizza!) is provided. Please
                    direct questions to
                    <a href="mailto:contact@tassa.dev">contact@tassa.dev</a>.
                </p>

                <div class="fellowship-toggles">
                    <button class="fellowship-toggle active" data-fellowship="technical">
                        Technical Fellowship
                    </button>
                    <button class="fellowship-toggle" data-fellowship="policy">
                        Policy Fellowship
                    </button>
                </div>

                <div class="fellowship-content">
                    <div class="fellowship-details" id="technical-details">
                        <div class="track-card">
                            <p>
                                Our technical fellowship covers the foundations of frontier AI
                                technology. Topics include model interpretability, goal
                                misgeneralization, reinforcement learning, oversight, red-teaming,
                                and more.
                            </p>
                            <p><strong>Sample curriculum:</strong></p>
                            <ul>
                                <li>
                                    <strong>Week 1:</strong>
                                    Introduction to modern machine learning and AI
                                </li>
                                <li>
                                    <strong>Week 2:</strong>
                                    AI risks and alignment challenges
                                </li>
                                <li>
                                    <strong>Week 3:</strong>
                                    Scalable oversight and adversarial training
                                </li>
                                <li>
                                    <strong>Week 4:</strong>
                                    Interpretability and model internals
                                </li>
                                <li>
                                    <strong>Week 5:</strong>
                                    Red-teaming and constitutional AI
                                </li>
                                <li>
                                    <strong>Week 6:</strong>
                                    Technical governance
                                </li>
                                <li>
                                    <strong>Week 7:</strong>
                                    Social impacts and civic AI
                                </li>
                                <li>
                                    <strong>Week 8:</strong>
                                    Field review and career opportunities
                                </li>
                            </ul>
                            <p>
                                <em>
                                    Note: We update and iterate our curricula each semester to
                                    reflect the latest developments in AI safety research.
                                </em>
                            </p>
                        </div>
                    </div>
                    <div class="fellowship-details" id="policy-details" style="display: none">
                        <div class="track-card">
                            <p>
                                Our policy fellowship discusses governance and policy solutions for
                                problems posed by transformative AI systems. We read draft
                                legislation, dissect governance frameworks, and develop a basic
                                understanding of the social, political, and technical challenges of
                                AI.
                            </p>
                            <p><strong>Sample curriculum:</strong></p>
                            <ul>
                                <li>
                                    <strong>Week 1:</strong>
                                    Introduction to modern machine learning and AI
                                </li>
                                <li>
                                    <strong>Week 2:</strong>
                                    AI risks and harms
                                </li>
                                <li>
                                    <strong>Week 3:</strong>
                                    Responsible scaling policies
                                </li>
                                <li>
                                    <strong>Week 4:</strong>
                                    AI companions, deepfakes, and misinformation
                                </li>
                                <li>
                                    <strong>Week 5:</strong>
                                    Compute governance
                                </li>
                                <li>
                                    <strong>Week 6:</strong>
                                    Energy and the environment
                                </li>
                                <li>
                                    <strong>Week 7:</strong>
                                    International and strategic frameworks
                                </li>
                                <li>
                                    <strong>Week 8:</strong>
                                    Governance regimes and next steps
                                </li>
                            </ul>
                            <p>
                                <em>
                                    Note: We update and iterate our curricula each semester to
                                    reflect the latest developments in AI governance and policy.
                                </em>
                            </p>
                        </div>
                    </div>
                </div>
            </article>
            <article class="program-card" id="research-support">
                <h3>Research Support & Funding</h3>
                <p>
                    Interested in doing AI Safety Research at Tufts? Submit a
                    <a href="https://forms.gle/N9YM62ianBtFcPjy6">Research Interest Form</a>
                    ! Applications are reviewed on a rolling basis.
                </p>
                <p>
                    We offer capstone and research support -- including compute funding -- to
                    members and those in our fellowships researching AI Safety issues. Please direct
                    questions to
                    <a href="mailto:contact@tassa.dev">contact@tassa.dev</a>.
                </p>
                <p>
                    In addition, several Tufts labs conduct AI Safety research, including but not
                    limited to:
                </p>
                <ul>
                    <li>
                        <a href="https://ai.tufts.edu/"
                            >Tufts Institute for Artificial Intelligence (TIAI)</a
                        >
                    </li>
                    <li>
                        <a href="https://hrilab.tufts.edu/">Human-Robot Interaction Lab (HRILab)</a>
                    </li>
                    <li>
                        <a href="https://sites.google.com/site/dekelreuth/gold-lab">
                            Goal Optimization using Learning and Decision-Making Lab (GOLD)
                        </a>
                    </li>
                    <li>
                        <a href="https://mulip.cs.tufts.edu/"
                            >Multimodal Learning, Interaction, and Perception Lab (MuLIP)</a
                        >
                    </li>
                    <li>
                        <a href="https://sites.tufts.edu/hilab/">Human Interaction Lab (HILab)</a>
                    </li>
                    <!-- <li><a href="">Lab</a></li> -->
                </ul>
            </article>
        </div>
    </div>
</section>
